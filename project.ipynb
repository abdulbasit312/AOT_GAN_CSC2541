{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AOT_GAN.src.model.aotgan import InpaintGenerator\n",
    "from AOT_GAN.src.loss.loss import L1, Style, Perceptual, smgan\n",
    "import torch\n",
    "from collections import namedtuple\n",
    "from attrdict import AttrDict\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision.transforms import ToTensor\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch import nn\n",
    "from AOT_GAN.src.model.common import BaseNetwork\n",
    "from AOT_GAN.src.model.aotgan import spectral_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Model and version\n",
    "\n",
    "# args_tuple = namedtuple(\"args\", [\"block_num\", \"rates\"])\n",
    "# args = args_tuple(block_num=8, rates=[1, 2, 4, 8])\n",
    "# model = InpaintGenerator(args).to(device)\n",
    "# model.load_state_dict(torch.load(\"/home/alex/Desktop/csc2541/AOT_GAN/experiments/places2/G0000000.pt\", map_location=device))\n",
    "# model.eval()\n",
    "\n",
    "# sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = np.zeros((512, 512, 1), np.uint8)\n",
    "# mask[:100, :, :] = 255\n",
    "# filename = \"AOT_GAN/my_examples/farmland.jpg\"\n",
    "# orig_img = cv2.resize(cv2.imread(filename, cv2.IMREAD_COLOR), (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def postprocess(image):\n",
    "#     image = torch.clamp(image, -1.0, 1.0)\n",
    "#     image = (image + 1) / 2.0 * 255.0\n",
    "#     image = image.permute(1, 2, 0)\n",
    "#     image = image.cpu().numpy().astype(np.uint8)\n",
    "#     return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     img_tensor = (ToTensor()(orig_img) * 2.0 - 1.0).unsqueeze(0).to(device)\n",
    "#     mask_tensor = (ToTensor()(mask)).unsqueeze(0).to(device)\n",
    "#     input_img = ((img_tensor * (1 - mask_tensor).float()) + mask_tensor).to(device)\n",
    "#     pred_tensor, x_mid = model(input_img, mask_tensor)\n",
    "#     comp_tensor = pred_tensor * mask_tensor + img_tensor * (1 - mask_tensor)\n",
    "\n",
    "#     pred_np = postprocess(pred_tensor[0])\n",
    "#     masked_np = postprocess(input_img[0])\n",
    "#     comp_np = postprocess(comp_tensor[0])\n",
    "\n",
    "#     cv2.imwrite(\"p.jpg\", comp_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InpaintingData(Dataset):\n",
    "    def __init__(self, root_dir: str, masks_dir: str):\n",
    "        super(Dataset, self).__init__()\n",
    "        # images \n",
    "        self.images = os.listdir(root_dir)\n",
    "        self.root_dir = root_dir\n",
    "        self.masks = os.listdir(masks_dir)\n",
    "        self.masks_dir = masks_dir\n",
    "\n",
    "        # augmentation\n",
    "        self.img_trans = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomResizedCrop(512),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(0.05, 0.05, 0.05, 0.05),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "        self.mask_trans = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(512, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation((0, 45), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load image\n",
    "        image_path = os.path.join(self.root_dir, self.images[index])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # get mask\n",
    "        rand_index = np.random.randint(0, len(self.masks_dir))\n",
    "        mask_path = os.path.join(self.masks_dir, self.masks[rand_index])\n",
    "        mask = Image.open(mask_path)\n",
    "        mask = mask.convert(\"L\")\n",
    "\n",
    "        # augment\n",
    "        image = self.img_trans(image) * 2.0 - 1.0\n",
    "        mask = F.to_tensor(self.mask_trans(mask))\n",
    "\n",
    "        return image, mask, image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = InpaintingData(\"data/images/train\", \"data/masks\")\n",
    "val = InpaintingData(\"data/images/val\", \"data/masks\")\n",
    "test = InpaintingData(\"data/images/test\", \"data/masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(BaseNetwork):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super(Discriminator, self).__init__()\n",
    "        inc = 3\n",
    "        self.conv = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(inc, 128, 4, stride=2, padding=1, bias=False)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            spectral_norm(nn.Conv2d(128, 512, 4, stride=1, padding=1, bias=False)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.conv(x)\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name, \n",
    "          student_generator,\n",
    "          teacher_generator,\n",
    "          discriminator,\n",
    "          L1_loss_weight=0.1,\n",
    "          style_loss_weight=250,\n",
    "          perceptual_loss_weight=0.1,\n",
    "          adversarial_loss_weight=0.01,\n",
    "          distillation_loss_weight=0.5,\n",
    "          num_epochs = 5,\n",
    "          gen_lr = 1e-4,\n",
    "          disc_lr = 1e-4,\n",
    "          a=0.5,\n",
    "          b=0.999,\n",
    "          save_every=3,\n",
    "          save_dir=\"models/\"):\n",
    "    writer = SummaryWriter()\n",
    "    iteration = 0\n",
    "\n",
    "    # Create losses\n",
    "    L1_loss = L1()\n",
    "    style_loss = Style()\n",
    "    percetual_loss = Perceptual()\n",
    "    adversarial_loss = smgan()\n",
    "    distillation_loss = torch.nn.MSELoss()\n",
    "\n",
    "    # get optimizers\n",
    "    optimG = torch.optim.Adam(student_generator.parameters(), lr=gen_lr, betas=(a, b))\n",
    "    optimD = torch.optim.Adam(discriminator.parameters(), lr=disc_lr, betas=(a, b))\n",
    "\n",
    "    print(\"Beginning Training\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "\n",
    "        for i, data in enumerate(tqdm(train_loader)):\n",
    "            # get batch of data\n",
    "            images, masks, _ = data\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            masked_images = (images * (1 - masks).float()) + masks\n",
    "\n",
    "            predicted_images, student_mids = student_generator(masked_images, masks)\n",
    "            with torch.no_grad():\n",
    "                teacher_predicted_images, teacher_mids = teacher_generator(masked_images, masks)\n",
    "            inpainted_images = (1 - masks) * images + masks * predicted_images\n",
    "\n",
    "            # losses\n",
    "            l1_loss_val = L1_loss(predicted_images, images)\n",
    "            style_loss_val = style_loss(predicted_images, images)\n",
    "            percetual_loss_val = percetual_loss(predicted_images, images)\n",
    "            distillation_loss_val = distillation_loss(student_mids, teacher_mids)\n",
    "            adversarial_disc_loss, adversarial_gen_loss = adversarial_loss(discriminator, inpainted_images, images, masks)\n",
    "\n",
    "            total_loss = (L1_loss_weight * l1_loss_val) + \\\n",
    "                         (style_loss_weight * style_loss_val) + \\\n",
    "                         (perceptual_loss_weight * percetual_loss_val) + \\\n",
    "                         (distillation_loss_weight * distillation_loss_val) + \\\n",
    "                         (adversarial_loss_weight * adversarial_gen_loss)\n",
    "        \n",
    "            optimG.zero_grad()\n",
    "            optimD.zero_grad()\n",
    "            total_loss.backward()\n",
    "            adversarial_disc_loss.backward()\n",
    "            optimG.step()\n",
    "            optimD.step()\n",
    "\n",
    "            writer.add_scalar(\"Loss/train/generator\", adversarial_gen_loss, iteration)\n",
    "            writer.add_scalar(\"Loss/train/discriminator\", adversarial_disc_loss, iteration)\n",
    "            writer.add_scalar(\"Loss/train/total\", total_loss, iteration)\n",
    "\n",
    "            iteration += 1\n",
    "        \n",
    "        if (epoch + 1) % save_every == 0:\n",
    "            torch.save(student_generator.module.state_dict(), os.path.join(save_dir, f\"student_generator_{epoch}.pt\"))\n",
    "            torch.save(discriminator.module.state_dict(), os.path.join(save_dir, f\"discriminator_{epoch}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create models\n",
    "teacher_model_args = AttrDict({\"block_num\":8, \"rates\":[1, 2, 4, 8]})\n",
    "teacher_model = InpaintGenerator(teacher_model_args).to(device)\n",
    "teacher_model.load_state_dict(torch.load(\"/home/alex/Desktop/csc2541/AOT_GAN/experiments/places2/G0000000.pt\", map_location=device))\n",
    "teacher_model.eval()\n",
    "\n",
    "half_size_args = AttrDict({\"block_num\": 4, \"rates\": [1, 2, 4, 8]})\n",
    "student_model = InpaintGenerator(half_size_args).to(device)\n",
    "\n",
    "disc = Discriminator().to(device)\n",
    "\n",
    "train(run_name=\"test\",\n",
    "      num_epochs=1,\n",
    "      student_generator=student_model,\n",
    "      teacher_generator=teacher_model,\n",
    "      discriminator=disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inpainting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
